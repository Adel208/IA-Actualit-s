require('dotenv').config();
const mongoose = require('mongoose');
const logger = require('../utils/logger');
const { initializeSources, scrapeAllSources, selectBestArticles } = require('../services/scraper');

/**
 * Job de scraping des actualit√©s
 */
async function scrapeNewsJob() {
  try {
    logger.info('üîç === D√âBUT DU JOB DE SCRAPING ===');

    // Connexion √† MongoDB
    await mongoose.connect(process.env.MONGODB_URI);
    logger.info('‚úÖ Connect√© √† MongoDB');

    // Initialiser les sources si n√©cessaire
    await initializeSources();

    // Scraper toutes les sources
    const articles = await scrapeAllSources();

    if (articles.length === 0) {
      logger.warn('‚ö†Ô∏è Aucun article trouv√©');
      return { success: true, articlesCount: 0 };
    }

    // S√©lectionner les meilleurs articles
    const bestArticles = selectBestArticles(articles, 5);

    logger.info(`‚úÖ ${bestArticles.length} articles s√©lectionn√©s pour g√©n√©ration`);
    logger.info('üîç === FIN DU JOB DE SCRAPING ===');

    return {
      success: true,
      articlesCount: articles.length,
      selectedCount: bestArticles.length,
      articles: bestArticles
    };

  } catch (error) {
    logger.error('‚ùå Erreur dans le job de scraping:', error);
    throw error;
  } finally {
    await mongoose.disconnect();
  }
}

// Si ex√©cut√© directement
if (require.main === module) {
  scrapeNewsJob()
    .then(result => {
      console.log('‚úÖ Job termin√©:', result);
      process.exit(0);
    })
    .catch(error => {
      console.error('‚ùå Erreur:', error);
      process.exit(1);
    });
}

module.exports = scrapeNewsJob;
